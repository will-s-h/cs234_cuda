Note: The previous attempt failed, so I tried a different kernel. Also, in the cpp_source, the get_init_inputs function returns an empty list as needed.
</think>

```
cuda_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void matvec_mult_ker(const float* A, const float* B, float* C, int M, int K) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= M || i >= K) return;
    float sum = 0.0f;
    for (int j = 0; j < K; j++) {
        sum += A[i * K + j] * B[j];
    }
    C[i] = sum;
}

torch::Tensor forward(torch::Tensor A, torch::Tensor B) {
    int M = A.size(0);
    int K = A.size(1);
    auto size = A.numel();
    auto output = torch::zeros_like(A);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    matvec_mult_ker<<<num_blocks, block_size>>>(A.data_ptr<float>(), B.data_ptr<float>(), output.data_ptr<float>(), M, K);

    return output;
}
"""

cpp_source = """
torch::Tensor forward(torch::Tensor A, torch::Tensor B) {
    int M = A.size(0);
    int K = A.size(1);
    int num_threads_per_block = 256;
    int num_blocks = (M * K + num_threads_per_block - 1) / num_threads_per_block;
    torch::Tensor C(M, 1);
    matvec_mult_ker<<<num_blocks, num_threads_per_block>>>(A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>(), M, K);
    return C;
}
"""
```